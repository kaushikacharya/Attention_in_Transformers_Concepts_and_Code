# Attention in Transformers: Concepts and Code in PyTorch

## Course Information

- Instructor: Josh Starmer
- [Course Website](https://www.deeplearning.ai/short-courses/attention-in-transformers-concepts-and-code-in-pytorch/)

## Course Contents

|#|     Lesson  |   Description   |
|-|-------------|-----------------|
|0|[Introduction](./notes/Lesson_0.md)|<ul><li>Challenges in earlier approaches of Machine Translation</li><li>History of Attention Mechanism</li><li>Models evolved from Encoder and Decoder</li><li>Course outline</li></ul>|
|1|[The Main Ideas Behind Transformers and Attention](./notes/Lesson_1.md)|<ul><li>Three main parts of Transformers</li><li>Self-attention explained with an example</li></ul>|
